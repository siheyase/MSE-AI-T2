import json
from pathlib import Path
from langchain_core.documents import Document
from langchain_text_splitters import RecursiveJsonSplitter
from langchain_ollama import OllamaEmbeddings
from langchain.storage import LocalFileStore
from langchain_community.docstore.in_memory import InMemoryDocstore
from langchain_community.vectorstores import FAISS
from langchain.retrievers.multi_vector import MultiVectorRetriever
import uuid
import faiss
from tqdm import tqdm


splitter = RecursiveJsonSplitter(max_chunk_size=2000)
embedding_model = OllamaEmbeddings(model="bge-m3")
vs_docs_path = Path.cwd() / "docs"
vs_path = Path.cwd() / "vs"
docs_store = LocalFileStore(vs_docs_path)

# ç¡®å®šè·ç¦»å‘é‡ç´¢å¼•
index = faiss.IndexFlatL2(len(embedding_model.embed_query("test")))
vectorstore = FAISS(
    embedding_function=embedding_model,
    index=index,
    docstore=InMemoryDocstore(),
    index_to_docstore_id={}
)

id_key = "doc_id"
retriever = MultiVectorRetriever(
    vectorstore=vectorstore,
    docstore=docs_store,
    id_key=id_key,
)


with open("./doc/medical.json", "r", encoding="utf-8") as f:
    total_lines = sum(1 for _ in f)

with open("./doc/medical.json", "r", encoding="utf-8") as f:
    for line in tqdm(f, total=total_lines, desc="Building FAISS index"):
        entry = json.loads(line)
        # æå–å…ƒæ•°æ®
        doc_id = str(uuid.uuid4())
        metadata = {
            id_key: doc_id,
            "name": entry.get("name", ""),
            "category": ",".join(entry.get("category", [])),
        }

        sub_docs = splitter.create_documents(
            texts=[entry],
            convert_lists=True,  # æ¨èè®¾ä¸º Trueï¼šèƒ½å°† list è½¬æ¢ä¸º dictï¼Œä¾¿äºåµŒå¥—å¤„ç†
            ensure_ascii=False,
            metadatas=[metadata],
        )
        retriever.vectorstore.add_documents(sub_docs)
        retriever.docstore.mset([(doc_id, str(entry).encode())])

        vectorstore.save_local(vs_path)

# âœ… è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
print(f"\nğŸ“¦ å½“å‰å‘é‡åˆ†å—æ•°é‡: {vectorstore.index.ntotal}")
print(f"ğŸ”— ç´¢å¼•åˆ°æ–‡æ¡£IDæ˜ å°„æ•°: {len(vectorstore.index_to_docstore_id)}")
