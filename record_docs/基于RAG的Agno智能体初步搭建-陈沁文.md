# agnoå’ŒRAGåŸºç¡€æ¡†æ¶éƒ¨ç½²
**è´Ÿè´£æˆå‘˜ï¼šé™ˆæ²æ–‡**
è´Ÿè´£å®ç°agnoåŸºç¡€æ¡†æ¶ä»¥åŠRAGåˆæ­¥pipelineæ­å»ºï¼ŒåŒ…å«å‘é‡æ•°æ®åº“åˆ›å»ºä»¥åŠæ£€ç´¢å™¨çš„æ„å»ºå’Œä¼˜åŒ–ï¼Œåˆæ­¥è¿è¡Œè·‘é€šé¡¹ç›®ã€‚

## ç¯å¢ƒé…ç½®
pythonç¯å¢ƒï¼špython3.12
ä¸»è¦ç”¨åˆ°çš„æ¡†æ¶å’Œåº“ï¼šagnoã€ollamaã€langchainã€faiss

åˆ›å»ºå¹¶æ¿€æ´»è™šæ‹Ÿç¯å¢ƒåå¯åŠ¨ollamaæœåŠ¡,æ£€æŸ¥ollamaç›‘å¬ç«¯å£11434ã€‚
```shell
ollama serve
curl http://localhost:11434
```

## faisså‘é‡æ•°æ®åº“åˆ›å»º
æ³¨æ„å®‰è£…ç‰ˆæœ¬å¿…é¡»ä¸º'-cu12',æ²¡æœ‰ä¼šæŠ¥é”™æ‰¾ä¸åˆ°ç‰ˆæœ¬ï¼Œæ¢å›½å†…é•œåƒæºåŠ é€Ÿä¸‹è½½ã€‚
```shell
pip install faiss-gpu-cu12
```
å®‰è£…langchainä»¥åŠç›¸å…³ä¾èµ–ï¼Œå…¶ä¸­langchain_communityåŒ…å«ç¬¬ä¸‰æ–¹é›†æˆï¼ˆfaissï¼‰ï¼Œlangchain_ollamaæ¶‰åŠlangchainå…³äºollamaçš„é›†æˆã€‚
```shell
pip install langchain langchain-community langchain_ollama
```

Embedding modelé€‰æ‹©bge-m3,é€šè¿‡ollamaéƒ¨ç½²ä»¥åŠè°ƒç”¨
>bge-m3 Embeddingæ¨¡å‹ä»¥å…¶åœ¨å¤šè¯­è¨€ã€å¤šåŠŸèƒ½å’Œå¤šç²’åº¦æ–¹é¢çš„å¤šåŠŸèƒ½æ€§è€Œè‘—ç§°ã€‚å®ƒæ”¯æŒè¶…è¿‡100ç§è¯­è¨€ï¼Œåœ¨å¤šè¯­è¨€å’Œè·¨è¯­è¨€æ£€ç´¢ä»»åŠ¡ä¸­å–å¾—äº†å“è¶Šçš„æ€§èƒ½ã€‚å®ƒå¯ä»¥åŒæ—¶æ‰§è¡ŒåµŒå…¥æ¨¡å‹çš„ä¸‰ç§å¸¸è§æ£€ç´¢åŠŸèƒ½ï¼šå¯†é›†æ£€ç´¢ã€å¤šå‘é‡æ£€ç´¢å’Œç¨€ç–æ£€ç´¢ï¼Œä¸ºç°å®ä¸–ç•Œçš„ä¿¡æ¯æ£€ç´¢åº”ç”¨æä¾›äº†ç»Ÿä¸€çš„æ¨¡å‹åŸºç¡€ã€‚å®ƒèƒ½å¤Ÿå¤„ç†ä¸åŒç²’åº¦çš„è¾“å…¥ï¼Œä»çŸ­å¥åˆ°å¤šè¾¾8192ä¸ªtokençš„é•¿æ–‡æ¡£ã€‚

ollamaæ‹‰å–bge-m3æ¨¡å‹
```shell
ollama pull bge-m3
```

æ¥ä¸‹æ¥å®ç°çŸ¥è¯†åº“æ–‡æ¡£medical.jsonçš„å‘é‡åŒ–å¹¶å­˜å‚¨åˆ°æœ¬åœ°faisså‘é‡æ•°æ®åº“
è€ƒè™‘åˆ°medical.jsonçš„æ•°æ®ç»“æ„ï¼Œå•æ¡å­—å…¸å¯¹åº”ä¸€ç§ç–¾ç—…çš„æ‰€æœ‰ä¿¡æ¯ï¼Œæ–‡æœ¬é•¿åº¦è¾ƒé•¿ï¼Œè‹¥ä»¥ä¸€èˆ¬çš„é€’å½’åˆ†å—æ–¹å¼è¿›è¡Œæ–‡æ¡£åˆ‡åˆ†ï¼Œå®¹æ˜“å°†åŒç§ç–¾ç—…çš„ä¿¡æ¯åˆ†æ•£åœ¨å¤šä¸ªåˆ†å—ä¸­ï¼Œä¸åˆ©äºå¬å›çš„å®Œæ•´æ€§ã€‚
å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œè‚ºæ³¡è›‹ç™½è´¨æ²‰ç§¯ç—‡çš„æè¿°å’Œç—‡çŠ¶ç­‰ä¿¡æ¯åˆ†æ•£åœ¨äº†ä¸¤ä¸ªåˆ†å—ï¼Œç¬¬äºŒä¸ªåˆ†å—ç¼ºå¤±æ‰€å±ç–¾ç—…åç§°çš„ä¿¡æ¯ï¼Œä¸æ˜“è¢«æ£€ç´¢åˆ°ã€‚ï¼ˆå³ä½¿è®¾ç½®max chunk size=2000è¯¥æ¡ç›®ä»è¢«åˆ†ä¸ºä¸¤ä¸ªåˆ†å—ï¼‰
![alt text](./image/image-cqw.png)
å› æ­¤æ£€ç´¢å™¨é‡‡ç”¨langchainçš„multivector retrieverï¼Œå°†å•ä¸ªç–¾ç—…æ¡ç›®ï¼ˆå³ä¸€ä¸ªå­—å…¸ï¼‰è§†ä½œçˆ¶æ–‡æ¡£ï¼Œå¯¹åº”çš„å­æ–‡æ¡£ä¸ºå…¶åˆ†å—ç»“æœï¼Œé€šè¿‡å‘é‡åŒ–å’Œæ£€ç´¢å­æ–‡æ¡£ï¼Œæœ€ç»ˆå¬å›æ‰€å±çš„çˆ¶æ–‡æ¡£ï¼Œæé«˜å¬å›ç‡ï¼Œä¿è¯ä¸Šä¸‹æ–‡ä¿¡æ¯çš„å®Œæ•´æ€§ã€‚
å…·ä½“å®ç°ä»£ç å¦‚ä¸‹,å­æ–‡æ¡£faisså‘é‡æ•°æ®åº“å­˜å‚¨è·¯å¾„ä¸ºå½“å‰è·¯å¾„/vs,çˆ¶æ–‡æ¡£å­˜å‚¨è·¯å¾„ä¸ºå½“å‰è·¯å¾„/docs,å­æ–‡æ¡£åˆ†å—ç­–ç•¥ä¸ºé€’å½’åˆ†å—ï¼Œæœ€å¤§åˆ†å—å¤§å°è®¾ç½®ä¸º2000.
```python
import json
from pathlib import Path
from langchain_core.documents import Document
from langchain_text_splitters import RecursiveJsonSplitter
from langchain_ollama import OllamaEmbeddings
from langchain.storage import LocalFileStore
from langchain_community.docstore.in_memory import InMemoryDocstore
from langchain_community.vectorstores import FAISS
from langchain.retrievers.multi_vector import MultiVectorRetriever
import uuid
import faiss
from tqdm import tqdm


splitter = RecursiveJsonSplitter(max_chunk_size=2000)
embedding_model = OllamaEmbeddings(model="bge-m3")
vs_docs_path = Path.cwd() / "docs"
vs_path = Path.cwd() / "vs"
docs_store = LocalFileStore(vs_docs_path)

# ç¡®å®šè·ç¦»å‘é‡ç´¢å¼•
index = faiss.IndexFlatL2(len(embedding_model.embed_query("test")))
vectorstore = FAISS(
    embedding_function=embedding_model,
    index=index,
    docstore=InMemoryDocstore(),
    index_to_docstore_id={}
)

id_key = "doc_id"
retriever = MultiVectorRetriever(
    vectorstore=vectorstore,
    docstore=docs_store,
    id_key=id_key,
)


with open("./doc/medical.json", "r", encoding="utf-8") as f:
    total_lines = sum(1 for _ in f)

with open("./doc/medical.json", "r", encoding="utf-8") as f:
    for line in tqdm(f, total=total_lines, desc="Building FAISS index"):
        entry = json.loads(line)
        # æå–å…ƒæ•°æ®
        doc_id = str(uuid.uuid4())
        metadata = {
            id_key: doc_id,
            "name": entry.get("name", ""),
            "category": ",".join(entry.get("category", [])),
        }

        sub_docs = splitter.create_documents(
            texts=[entry],
            convert_lists=True,  # æ¨èè®¾ä¸º Trueï¼šèƒ½å°† list è½¬æ¢ä¸º dictï¼Œä¾¿äºåµŒå¥—å¤„ç†
            ensure_ascii=False,
            metadatas=[metadata],
        )
        retriever.vectorstore.add_documents(sub_docs)
        retriever.docstore.mset([(doc_id, str(entry).encode())])

        vectorstore.save_local(vs_path)

# è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
print(f"\n å½“å‰å‘é‡åˆ†å—æ•°é‡: {vectorstore.index.ntotal}")
print(f" ç´¢å¼•åˆ°æ–‡æ¡£IDæ˜ å°„æ•°: {len(vectorstore.index_to_docstore_id)}")
```


é¦–å…ˆåªå‘é‡åŒ–å‰ä¸¤æ¡æ•°æ®è¿›è¡Œæµ‹è¯•ï¼Œæµ‹è¯•ä»£ç å¦‚ä¸‹ï¼š
```python
import json
from pathlib import Path
from langchain_ollama import OllamaEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.retrievers.multi_vector import MultiVectorRetriever
from langchain.storage import LocalFileStore

vs_path = Path.cwd() / "vs"
vs_docs_path = Path.cwd() / "docs"
embedding_model = OllamaEmbeddings(model="bge-m3")
vectorstore = FAISS.load_local(vs_path, embedding_model, allow_dangerous_deserialization=True)
docstore = LocalFileStore(vs_docs_path)
retriever = MultiVectorRetriever(
    vectorstore=vectorstore,
    docstore=docstore,
    id_key="doc_id",
)

# è¿›è¡ŒæŸ¥è¯¢æµ‹è¯•
query = "å‡ºç°å‘¼å¸å›°éš¾æ€ä¹ˆåŠï¼Ÿ"
results = retriever.invoke(query)

for i, raw_bytes in enumerate(results):
    print(f"\n--- åŸå§‹æ–‡æ¡£ {i+1} ---")
    decoded = raw_bytes.decode("utf-8")
    # è½¬æ¢ä¸º JSON å¯¹è±¡ï¼ˆå­—å…¸ï¼‰
    try:
        doc_dict = eval(decoded)
        print(json.dumps(doc_dict, indent=2, ensure_ascii=False))
    except Exception as e:
        print("âš ï¸ è§£ç å¤±è´¥:", e)


# éå† vectorstore ä¸­çš„æ‰€æœ‰åˆ†å—ï¼Œ
print(f"ğŸ“¦ å½“å‰å‘é‡æ•°é‡: {vectorstore.index.ntotal}")
print(f"ğŸ”— ç´¢å¼•åˆ°æ–‡æ¡£IDæ˜ å°„æ•°: {len(vectorstore.index_to_docstore_id)}")

for i in range(vectorstore.index.ntotal):
    doc_id = vectorstore.index_to_docstore_id[i]
    doc = vectorstore.docstore.search(doc_id)

    print(f"\n--- Chunk {i+1} ---")
    print(f"ğŸ†” æ–‡æ¡£ID: {doc_id}")
    print(f"ğŸ“„ å†…å®¹ç‰‡æ®µ:\n{doc.page_content[:300]}...")
    print(f"ğŸ“ å…ƒæ•°æ®: {doc.metadata}")
```
ä¸‹é¢ä¸¤å¼ å›¾åˆ†åˆ«æ˜¯æŸ¥è¯¢æµ‹è¯•çš„å¬å›æ–‡æ¡£å’Œå‘é‡åº“æ‰€æœ‰åˆ†å—çš„æƒ…å†µï¼Œå¯ä»¥çœ‹å‡ºæµ‹è¯•å¬å›2ä¸ªå®Œæ•´æ•°æ®æ¡ç›®ï¼Œè€Œä¸æ˜¯åˆ†å—ï¼Œå‘é‡åº“åˆ†å—æ€»æ•°ä¸º7ï¼Œmetadataä¸­çš„metadata doc_idä»…ä¸¤ç§ï¼Œä¸çˆ¶æ–‡æ¡£ç›¸å¯¹åº”ï¼Œè¯´æ˜ä»£ç é€»è¾‘ç¬¦åˆmultivector retrieverã€‚
![alt text](./image/image-cqw-2.png)
![alt text](./image/image-cqw-3.png)

æœ€åå®Œæˆæ•´ä¸ªçŸ¥è¯†æ–‡æ¡£çš„å‘é‡åŒ–ï¼Œç”¨æ—¶1hï¼Œå‘é‡æ•°æ®åº“ä¿¡æ¯å¦‚ä¸‹![alt text](./image/image-cqw-1.png)

## ç»“åˆRAGçš„è‡ªé€‚åº”æ£€ç´¢Agno agentåˆæ­¥æ­å»º
å®‰è£…agno
```shell
pip install -U agno
```
é¦–å…ˆï¼Œæ˜ç¡®å…³äºagentè®¾è®¡çš„æ„æƒ³  
|åŠŸèƒ½|è¯´æ˜|
|---|---|
|æ™®é€šå¯¹è¯|ç»Ÿä¸€ç®¡ç†ä¸Šä¸‹æ–‡ï¼Œä¿ç•™å¯¹è¯å†å²ï¼ŒåŒ…å«å†å²æ£€ç´¢å¬å›ç»“æœ|
|è‡ªé€‚åº”æ£€ç´¢ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦æ£€ç´¢|è®¾è®¡prompt COTåˆ¤æ–­æ˜¯å¦éœ€è¦æ£€ç´¢ï¼Œæ— éœ€æ£€ç´¢çš„æƒ…å†µåŒ…æ‹¬ç”¨æˆ·å†æ¬¡çš„è¯¢é—®å¯åŸºäºå·²æœ‰å¯¹è¯å†å²å›ç­”ï¼Œæˆ–è€…ç”¨æˆ·è¾“å…¥ä¸æ˜¯æŸ¥è¯¢ï¼Œè€Œæ˜¯å›ç­”æ¨¡å‹çš„å¼•å¯¼é—®é¢˜ï¼ˆä¸è¿‡åœ¨è¡¥å……äº†ç—…ç—‡ä¿¡æ¯åå¯èƒ½ä¹Ÿéœ€è¦æ–°çš„æ£€ç´¢è¡¥å……çŸ¥è¯†ï¼‰ï¼Œè¿˜æœ‰ç”¨æˆ·è¾“å…¥è¦æ±‚ç”Ÿæˆæˆ–è€…ç‚¹å‡»äº¤äº’æŒ‰é’®è¦æ±‚ç”ŸæˆæŠ¥å‘Šï¼Œè¿™ç§æƒ…å†µä¹Ÿæ— éœ€æ£€ç´¢ï¼Œå±äºæ€»ç»“|
|æ£€ç´¢åå›ç­”|ä¾æ®å¬å›çŸ¥è¯†å›ç­”|
|å¼•å¯¼æé—®/æ”¶é›†æ›´å¤šä¿¡æ¯ï¼Œç»“å°¾ç”Ÿæˆå¼•å¯¼ä¿¡æ¯|åœ¨å›ç­”åè‡ªåŠ¨å»ºè®®ç”¨æˆ·è¡¥å……ä»€ä¹ˆç—‡çŠ¶|
|ç—…ä¾‹æ€»ç»“/æŠ¥å‘Šç”Ÿæˆ|æ¨¡å‹ç”¨å†å²å¯¹è¯è°ƒç”¨ç”Ÿæˆå·¥å…·ï¼Œmarkdownï¼Œåœ¨streamlitç•Œé¢å¯ä¾›ä¸‹è½½|

æ¥ä¸‹æ¥å®Œæˆè‡ªé€‚åº”æ£€ç´¢agentã€‚
èµ·åˆè®¤ä¸ºéœ€è¦æ„å»ºä¸¤ä¸ªagentï¼Œä¸€ä¸ªè´Ÿè´£åˆ¤æ–­æ˜¯å¦éœ€è¦æ£€ç´¢ï¼Œä¸€ä¸ªè´Ÿè´£å®é™…æ£€ç´¢ï¼›ä½†åœ¨å®ç°è¿‡ç¨‹ä¸­å‘ç°ä»…éœ€ä¸€ä¸ªagentå³å¯ï¼Œè¯¥agentåœ¨åˆ¤æ–­éœ€è¦æ£€ç´¢åè°ƒç”¨æ£€ç´¢å·¥å…·retrieve_medicalå®ŒæˆRAGè¿‡ç¨‹ã€‚
å…¶ä¸­retrieve_medicalæ˜¯éœ€è¦å®ç°çš„å‡½æ•°ï¼ŒagentåŸºäºæŸ¥è¯¢å’Œå¯¹è¯å†å²åœ¨åˆ¤æ–­éœ€è¦æ£€ç´¢åä¼šé€šè¿‡æ¨ç†è‡ªåŠ¨æå–ç”¨äºæ£€ç´¢çš„æŸ¥è¯¢è¯­å¥ï¼Œä½œä¸ºå‚æ•°queryä¼ å…¥retrieve_medicalå¹¶è°ƒç”¨ï¼Œretrieve_medicaåœ¨faisså‘é‡æ•°æ®åº“æ£€ç´¢å¬å›ç›¸å…³çš„çŸ¥è¯†æ–‡æ¡£ä½œä¸ºè¾“å…¥ç”Ÿæˆæ¨¡å‹çš„ä¸Šä¸‹æ–‡ï¼Œæœ€ç»ˆæŒ‡å¯¼æ¨¡å‹å›ç­”ã€‚
æ­¤å¤„çš„retrieve_medicalæˆ‘ä»…å®Œæˆäº†åŸºç¡€çš„æ£€ç´¢å’Œä¸Šä¸‹æ–‡è¿”å›åŠŸèƒ½ï¼Œåç»­RAGä¼˜åŒ–ç”±å…¶ä»–åŒå­¦è´Ÿè´£ã€‚
ç”Ÿæˆæ¨¡å‹ï¼ˆDEFAULT_MODELï¼‰é€‰æ‹©qwen2.5:14b-instruct-fp16ï¼ŒåŒæ ·éœ€è¦é€šè¿‡ollamaæ‹‰å–å’Œè°ƒç”¨ã€‚TOP_Kè®¾ç½®ä¸º2ã€‚
```shell
ollama pull qwen2.5:14b-instruct-fp16
```
>Qwen2.5æ˜¯ä¸€ç³»åˆ—å…¨é¢çš„å¤§å‹è¯­è¨€æ¨¡å‹ (LLM)ï¼Œæ—¨åœ¨æ»¡è¶³å¤šæ ·åŒ–éœ€æ±‚ã€‚ä¸ä¹‹å‰çš„ç‰ˆæœ¬ç›¸æ¯”ï¼ŒQwen 2.5 åœ¨è®­ç»ƒå‰å’Œè®­ç»ƒåé˜¶æ®µéƒ½å¾—åˆ°äº†æ˜¾è‘—æ”¹è¿›ã€‚instructæ˜¯ç»è¿‡æŒ‡ä»¤å¾®è°ƒçš„ç‰ˆæœ¬ï¼Œä¸“é—¨ç”¨äºç†è§£å’Œæ‰§è¡Œç‰¹å®šçš„æŒ‡ä»¤ã€‚å®ƒåœ¨é€šç”¨è¯­è¨€æ¨¡å‹çš„åŸºç¡€ä¸Šï¼Œå¢åŠ äº†å¯¹æŒ‡ä»¤çš„ç†è§£å’Œæ‰§è¡Œèƒ½åŠ›ï¼Œä½¿å…¶æ›´é€‚åˆå¤„ç†æŒ‡ä»¤å¼çš„ä»»åŠ¡ï¼Œå¦‚ç”Ÿæˆç‰¹å®šæ ¼å¼çš„æ–‡æœ¬ã€å›ç­”ç‰¹å®šç±»å‹çš„é—®é¢˜ç­‰ã€‚

agentä»£ç å¦‚ä¸‹
```python
# agent.py
from agno.agent import Agent
from agno.models.ollama import Ollama
from agno.tools.reasoning import ReasoningTools
from config.settings import DEFAULT_MODEL, VS_PATH, VS_DOCS_PATH, EMBEDDING_MODEL, TOP_K, SEARCH_TYPE
from langchain_ollama import OllamaEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.retrievers.multi_vector import MultiVectorRetriever
from langchain.storage import LocalFileStore
from typing import Annotated
import json
import logging
from textwrap import dedent

logger = logging.getLogger(__name__)

# åˆå§‹åŒ–å‘é‡æ•°æ®åº“ç»„ä»¶ä¸€æ¬¡ï¼Œé¿å…æ¯æ¬¡è°ƒç”¨éƒ½é‡å¤åŠ è½½
embedding_model = OllamaEmbeddings(model=EMBEDDING_MODEL)
vectorstore = FAISS.load_local(VS_PATH, embedding_model, allow_dangerous_deserialization=True)
docstore = LocalFileStore(VS_DOCS_PATH)
retriever = MultiVectorRetriever(
    vectorstore=vectorstore,
    docstore=docstore,
    id_key="doc_id",
    search_type=SEARCH_TYPE,
    search_kwargs={"k": TOP_K},
)

def retrieve_medical(query: Annotated[str, "éœ€è¦æŸ¥è¯¢çš„åŒ»å­¦é—®é¢˜"]) -> str:
    results = retriever.invoke(query)
    contexts = []
    for raw_bytes in results:
        try:
            decoded = raw_bytes.decode("utf-8")
            doc_dict = eval(decoded)
            contexts.append(json.dumps(doc_dict, ensure_ascii=False))
        except Exception as e:
            logger.warning(f"è§£ç å¤±è´¥: {e}")
    return "\n\n".join(contexts) if contexts else "æœªæ‰¾åˆ°ç›¸å…³åŒ»å­¦èµ„æ–™ã€‚"


def get_agent(model_id: str = DEFAULT_MODEL, session_id=None, user_id=None) -> Agent:
    return Agent(
        name="Medical Assistant",
        model=Ollama(id=model_id),
        instructions=dedent("""\
                        ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥å›ç­”ç”¨æˆ·çš„å„ç§é—®é¢˜ã€‚
                        å‘é‡æ•°æ®åº“æ•°æ®æ¥æºæƒå¨çš„åŒ»è¯ç½‘ç«™â€œå¯»åŒ»é—®è¯â€ç½‘ï¼Œå¤„ç†æˆç»“æ„åŒ–æ•°æ®
                        æ•°æ®ç¤ºä¾‹ï¼š
                        {
                        "name": "è‚ºæ³¡è›‹ç™½è´¨æ²‰ç§¯ç—‡",
                        "desc": "è‚ºæ³¡è›‹ç™½è´¨æ²‰ç§¯ç—‡(ç®€ç§°PAP)...ç”·æ€§å‘ç—…çº¦3å€äºå¥³æ€§ã€‚",
                        "category": ["ç–¾ç—…ç™¾ç§‘","å†…ç§‘","å‘¼å¸å†…ç§‘"],
                        "prevent": "1ã€é¿å…æ„ŸæŸ“åˆ†æ”¯æ†èŒç—…...å› æ­¤ç›®å‰ä¸€èˆ¬è®¤ä¸ºæœ¬ç—…ä¸æ¸…é™¤èƒ½åŠ›ä¸‹é™æœ‰å…³ã€‚",
                        "symptom": ["ç´«ç»€","èƒ¸ç—›","å‘¼å¸å›°éš¾","ä¹åŠ›","æ¯“å“"],
                        "acompany": ["å¤šé‡è‚ºéƒ¨æ„ŸæŸ“"],
                        "cure_department": ["å†…ç§‘","å‘¼å¸å†…ç§‘"],
                        "cure_way": ["æ”¯æ°”ç®¡è‚ºæ³¡çŒæ´—"],
                        "check": ["èƒ¸éƒ¨CTæ£€æŸ¥","è‚ºæ´»æ£€","æ”¯æ°”ç®¡é•œæ£€æŸ¥"],
                        "recommand_drug":...,
                        "drug_detail":...
                        }
                        å¦‚æœä½ è®¤ä¸ºç”¨æˆ·å½“å‰çš„é—®é¢˜æ— æ³•å‡­å€Ÿè‡ªèº«å†…éƒ¨çŸ¥è¯†ç›´æ¥å›ç­”ï¼Œéœ€è¦æ£€ç´¢ç±»ä¼¼ä¸Šè¿°çš„åŒ»å­¦çŸ¥è¯†ï¼Œé‚£ä¹ˆä½¿ç”¨retrieve_medicalå·¥å…·ï¼Œä¾‹å¦‚ï¼šretrieve_medical(query)ï¼Œå¦åˆ™æ— éœ€æ£€ç´¢ç›´æ¥å›ç­”\
                    """),
        tools=[ReasoningTools(add_instructions=True), retrieve_medical],
        show_tool_calls=True,
        markdown=True,
    )
```
è¿è¡Œmain.pyæ–‡ä»¶æµ‹è¯•
```python
# main.py
from models.agent import get_agent

if __name__ == "__main__":

    agent = get_agent()
    # user_input = "ä»€ä¹ˆæ˜¯ç—…æ¯’æ€§å¿ƒè‚Œç‚ï¼Ÿ"
    user_input = "ä¸­å›½çš„é¦–éƒ½åœ¨å“ªï¼Ÿ"
    res = agent.run(user_input)
```
ä¸¤ä¸ªæµ‹è¯•é—®é¢˜å‰è€…éœ€è¦æ£€ç´¢ï¼Œåè€…ä¸éœ€è¦ï¼š1.  "ä»€ä¹ˆæ˜¯ç—…æ¯’æ€§å¿ƒè‚Œç‚ï¼Ÿ" 2. "ä¸­å›½çš„é¦–éƒ½åœ¨å“ªï¼Ÿ"ã€‚
æµ‹è¯•æ•ˆæœå¦‚ä¸‹ï¼Œå¯ä»¥çœ‹åˆ°agentå¯ä»¥å®ç°è¯¥æ„å›¾åˆ†ç±»ï¼Œè°ƒç”¨ç›¸åº”çš„å·¥å…·ã€‚
![alt text](./image/image-cqw-4.png)
![alt text](./image/image-cqw-5.png)
![alt text](./image/image-cqw-6.png)
